{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 数据生成（增强和预处理）\n",
    "def generate_synthetic_data(num_samples=1000, image_size=(64, 64)):\n",
    "    X = np.random.rand(num_samples, *image_size)\n",
    "    y = np.random.rand(num_samples, *image_size)\n",
    "\n",
    "    # 数据增强（旋转、平移、加噪声等）\n",
    "    X = np.array([np.rot90(x, np.random.randint(0, 4)) for x in X])\n",
    "    y = np.array([np.rot90(y_, np.random.randint(0, 4)) for y_ in y])\n",
    "    X += np.random.normal(0, 0.01, X.shape)\n",
    "    return X, y\n",
    "\n",
    "# U-Net结构，支持可变规模\n",
    "def build_unet(input_shape=(64, 64, 1), base_filters=32, depth=3):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    skips = []\n",
    "    # 编码器\n",
    "    for i in range(depth):\n",
    "        x = layers.Conv2D(base_filters * 2**i, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.Conv2D(base_filters * 2**i, (3, 3), activation='relu', padding='same')(x)\n",
    "        skips.append(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "    # Bottleneck\n",
    "    x = layers.Conv2D(base_filters * 2**depth, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(base_filters * 2**depth, (3, 3), activation='relu', padding='same')(x)\n",
    "    # 解码器\n",
    "    for i in reversed(range(depth)):\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        x = layers.Concatenate()([x, skips[i]])\n",
    "        x = layers.Conv2D(base_filters * 2**i, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.Conv2D(base_filters * 2**i, (3, 3), activation='relu', padding='same')(x)\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='linear')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse', metrics=['mse', 'mae'])\n",
    "    return model\n",
    "\n",
    "# 生成数据并进行训练\n",
    "X, y = generate_synthetic_data()\n",
    "\n",
    "# 数据维度调整\n",
    "X = X[..., np.newaxis]\n",
    "y = y[..., np.newaxis]\n",
    "\n",
    "# 不同规模的模型参数\n",
    "model_configs = [\n",
    "    {'name': 'Small U-Net', 'base_filters': 16, 'depth': 2},\n",
    "    {'name': 'Medium U-Net', 'base_filters': 32, 'depth': 3},\n",
    "    {'name': 'Large U-Net', 'base_filters': 64, 'depth': 4},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "result_dir = os.path.join(os.path.dirname(__file__), 'results')\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "for config in model_configs:\n",
    "    print(f\"\\n训练模型: {config['name']}\")\n",
    "    model = build_unet(input_shape=(64, 64, 1), base_filters=config['base_filters'], depth=config['depth'])\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    history = model.fit(X, y, epochs=60, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "    val_mse = history.history['val_mse'][-1]\n",
    "    val_mae = history.history['val_mae'][-1]\n",
    "    results.append({'name': config['name'], 'val_mse': val_mse, 'val_mae': val_mae, 'history': history})\n",
    "    print(f\"最终验证集MSE: {val_mse:.4f}, MAE: {val_mae:.4f}\")\n",
    "    # 保存每个模型的损失曲线\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['val_loss'], label=f\"{config['name']} Val Loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Val MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'{config['name']} 验证损失曲线')\n",
    "    plt.savefig(os.path.join(result_dir, f\"{config['name'].replace(' ', '_')}_val_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 绘制不同规模模型的损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "for res in results:\n",
    "    plt.plot(res['history'].history['val_loss'], label=f\"{res['name']} Val Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Val MSE Loss')\n",
    "plt.legend()\n",
    "plt.title('不同规模U-Net模型验证损失对比')\n",
    "plt.savefig(os.path.join(result_dir, \"all_models_val_loss.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 随机选取样本进行对比可视化（用最大规模模型）\n",
    "idx = np.random.randint(0, X.shape[0])\n",
    "sample_input = X[idx:idx+1]\n",
    "sample_true = y[idx]\n",
    "best_model = build_unet(input_shape=(64, 64, 1), base_filters=64, depth=4)\n",
    "best_model.fit(X, y, epochs=60, batch_size=32, validation_split=0.2, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)], verbose=0)\n",
    "sample_pred = best_model.predict(sample_input)[0]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Input Data')\n",
    "plt.imshow(sample_input[0, :, :, 0], cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('True Property')\n",
    "plt.imshow(sample_true[:, :, 0], cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Predicted Property (Large U-Net)')\n",
    "plt.imshow(sample_pred[:, :, 0], cmap='gray')\n",
    "plt.savefig(os.path.join(result_dir, \"comparison_large_unet.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 保存所有模型验证集MSE和MAE到txt\n",
    "with open(os.path.join(result_dir, \"metrics.txt\"), \"w\") as f:\n",
    "    for res in results:\n",
    "        f.write(f\"{res['name']}: MSE={res['val_mse']:.4f}, MAE={res['val_mae']:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
