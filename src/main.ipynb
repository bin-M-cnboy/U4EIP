{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ==================== é…ç½®å‚æ•° ====================\n",
    "CONFIG = {\n",
    "    'num_samples': 500,\n",
    "    'image_size': (64, 64),\n",
    "    'base_filters': 32,\n",
    "    'depth': 3,\n",
    "    'epochs': 60,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "}\n",
    "\n",
    "# ==================== æ•°æ®ç”Ÿæˆ ====================\n",
    "def create_circle_mask(size=64, center_shift=0):\n",
    "    \"\"\"ç”Ÿæˆå«æœ‰åœ†å½¢çš„çŸ©é˜µ\"\"\"\n",
    "    y, x = np.ogrid[-1:1:size*1j, -1:1:size*1j]\n",
    "    radius = 0.5\n",
    "    circle = (x**2 + y**2) <= radius**2\n",
    "    \n",
    "    # åœ†å½¢å†…éƒ¨æ•°å€¼å¤§ï¼ˆ1.0ï¼‰ï¼Œå¤–éƒ¨æ•°å€¼å°ï¼ˆ0.2ï¼‰\n",
    "    mask = np.where(circle, 1.0, 0.2)\n",
    "    return mask\n",
    "\n",
    "def generate_synthetic_data(num_samples=500, image_size=(64, 64)):\n",
    "    \"\"\"ç”Ÿæˆåœ†å½¢æ•°æ®é›†\"\"\"\n",
    "    X = np.array([create_circle_mask(image_size[0]) for _ in range(num_samples)])\n",
    "    y = np.array([create_circle_mask(image_size[0]) for _ in range(num_samples)])\n",
    "    \n",
    "    # æ•°æ®å¢å¼ºï¼šæ—‹è½¬ã€åŠ å™ªå£°\n",
    "    X = np.array([np.rot90(x, np.random.randint(0, 4)) for x in X])\n",
    "    y = np.array([np.rot90(y_, np.random.randint(0, 4)) for y_ in y])\n",
    "    X += np.random.normal(0, 0.02, X.shape)\n",
    "    X = np.clip(X, 0, 1)\n",
    "    \n",
    "    # å½’ä¸€åŒ–\n",
    "    X = (X - X.min()) / (X.max() - X.min() + 1e-8)\n",
    "    y = (y - y.min()) / (y.max() - y.min() + 1e-8)\n",
    "    return X, y\n",
    "\n",
    "def postprocess_prediction(pred, threshold=0.8):\n",
    "    \"\"\"æŒ‰èŒƒå›´å¼ºåŒ–é¢„æµ‹ç»“æœï¼š>0.8å‘ä¸Šå–æ•´ï¼Œ<0.3å‘ä¸‹å–æ•´\"\"\"\n",
    "    result = pred.copy()\n",
    "    result[result >= threshold] = 1.0\n",
    "    result[result <= 0.3] = 0.0\n",
    "    return result\n",
    "\n",
    "# ==================== æ¨¡å‹æ„å»º ====================\n",
    "def build_unet(input_shape=(64, 64, 1), base_filters=32, depth=3):\n",
    "    \"\"\"è½»é‡çº§U-Net\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    skips = []\n",
    "    \n",
    "    # ç¼–ç å™¨\n",
    "    for i in range(depth):\n",
    "        x = layers.Conv2D(base_filters * 2**i, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.Conv2D(base_filters * 2**i, (3, 3), activation='relu', padding='same')(x)\n",
    "        skips.append(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Bottleneck\n",
    "    x = layers.Conv2D(base_filters * 2**depth, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(base_filters * 2**depth, (3, 3), activation='relu', padding='same')(x)\n",
    "    \n",
    "    # è§£ç å™¨\n",
    "    for i in reversed(range(depth)):\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        x = layers.Concatenate()([x, skips[i]])\n",
    "        x = layers.Conv2D(base_filters * 2**i, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.Conv2D(base_filters * 2**i, (3, 3), activation='relu', padding='same')(x)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=CONFIG['learning_rate']),\n",
    "                  loss='binary_crossentropy', metrics=['mse', 'mae'])\n",
    "    return model\n",
    "\n",
    "# ==================== ä¸»ç¨‹åº ====================\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "print(\"ç”Ÿæˆåœ†å½¢æ•°æ®é›†...\")\n",
    "X, y = generate_synthetic_data(CONFIG['num_samples'], CONFIG['image_size'])\n",
    "X = X[..., np.newaxis]\n",
    "y = y[..., np.newaxis]\n",
    "\n",
    "# åˆ›å»ºç»“æœç›®å½•\n",
    "result_dir = os.path.join('results')\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "print(\"è®­ç»ƒè½»é‡çº§U-Netæ¨¡å‹...\")\n",
    "model = build_unet(input_shape=(64, 64, 1), base_filters=CONFIG['base_filters'], depth=CONFIG['depth'])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X, y, epochs=CONFIG['epochs'], batch_size=CONFIG['batch_size'],\n",
    "                   validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "val_mse = history.history['val_mse'][-1]\n",
    "val_mae = history.history['val_mae'][-1]\n",
    "print(f\"æœ€ç»ˆéªŒè¯é›†MSE: {val_mse:.4f}, MAE: {val_mae:.4f}\")\n",
    "\n",
    "# ä¿å­˜æŸå¤±æ›²çº¿\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('U-Netè®­ç»ƒæ›²çº¿')\n",
    "plt.savefig(os.path.join(result_dir, \"training_loss.png\"), dpi=100)\n",
    "plt.close()\n",
    "\n",
    "# é¢„æµ‹å¹¶å¯è§†åŒ–\n",
    "idx = np.random.randint(0, X.shape[0])\n",
    "sample_input = X[idx:idx+1]\n",
    "sample_true = y[idx]\n",
    "sample_pred = model.predict(sample_input)[0]\n",
    "sample_pred_enhanced = postprocess_prediction(sample_pred, threshold=0.8)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title('Input (Circle)')\n",
    "plt.imshow(sample_input[0, :, :, 0], cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title('True Label')\n",
    "plt.imshow(sample_true[:, :, 0], cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title('Raw Prediction')\n",
    "plt.imshow(sample_pred[:, :, 0], cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title('Enhanced Prediction')\n",
    "plt.imshow(sample_pred_enhanced[:, :, 0], cmap='gray')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(result_dir, \"prediction_comparison.png\"), dpi=100)\n",
    "plt.close()\n",
    "\n",
    "# ä¿å­˜æŒ‡æ ‡\n",
    "with open(os.path.join(result_dir, \"metrics.txt\"), \"w\") as f:\n",
    "    f.write(f\"Circle Detection U-Net\\n\")\n",
    "    f.write(f\"Val MSE: {val_mse:.4f}\\n\")\n",
    "    f.write(f\"Val MAE: {val_mae:.4f}\\n\")\n",
    "    f.write(f\"Samples: {CONFIG['num_samples']}, Epochs: {len(history.history['loss'])}\\n\")\n",
    "\n",
    "print(\"è®­ç»ƒå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°resultsç›®å½•ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c861284",
   "metadata": {},
   "source": [
    "# U4EIPï¼šåŸºäº U-Net çš„ç”µç£ç‰¹æ€§æ¢å¤ç³»ç»Ÿ\n",
    "\n",
    "## ğŸ“‹ æ¦‚è¿°\n",
    "\n",
    "ä¸€ä¸ªåŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„ç”µç£ç‰¹æ€§æ¢å¤ç³»ç»Ÿï¼Œé€šè¿‡è½»é‡çº§U-Netæ¨¡å‹ä»ç”µç£æ³¢ä¼ æ’­æ•°æ®ä¸­ç²¾ç¡®æ¢å¤ä»‹è´¨çš„ç”µç£ç‰¹æ€§ï¼ˆå¦‚ä»‹ç”µå¸¸æ•°åˆ†å¸ƒï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ è®¾è®¡åŸç†\n",
    "\n",
    "### 1. **é—®é¢˜å®šä¹‰**\n",
    "- **è¾“å…¥**ï¼šæ¨¡æ‹Ÿçš„ç”µç£æ³¢ä¼ æ’­æ•°æ®ï¼ˆ64Ã—64çŸ©é˜µï¼‰\n",
    "- **è¾“å‡º**ï¼šä»‹è´¨çš„ç”µç£ç‰¹æ€§åˆ†å¸ƒï¼ˆ64Ã—64çŸ©é˜µï¼‰\n",
    "- **ä»»åŠ¡**ï¼šä»è§‚æµ‹æ•°æ®åæ¼”ä»‹è´¨ç‰©ç†å‚æ•°\n",
    "\n",
    "### 2. **æ ¸å¿ƒæ€è·¯**\n",
    "\n",
    "#### æ•°æ®å±‚ï¼šåœ†å½¢å›¾æ¡ˆç”Ÿæˆ\n",
    "```\n",
    "åœ†å½¢æ©è†œ (Circle Mask)\n",
    "â”œâ”€ åœ†å¿ƒå†…éƒ¨: æ•°å€¼ = 1.0 (æ·±è‰²ï¼Œä»£è¡¨é«˜ä»‹ç”µå¸¸æ•°)\n",
    "â”œâ”€ åœ†å¿ƒå¤–éƒ¨: æ•°å€¼ = 0.2 (æµ…è‰²ï¼Œä»£è¡¨ä½ä»‹ç”µå¸¸æ•°)\n",
    "â””â”€ æ¨¡æ‹ŸçœŸå®ç”µç£ä»‹è´¨çš„ç©ºé—´åˆ†å¸ƒç‰¹å¾\n",
    "```\n",
    "\n",
    "æ•°æ®å¢å¼ºç­–ç•¥ï¼š\n",
    "- **æ—‹è½¬å˜æ¢**ï¼šå¢åŠ æ¨¡å‹å¯¹æ–¹å‘ä¸å˜æ€§çš„å­¦ä¹ \n",
    "- **é«˜æ–¯å™ªå£°**ï¼šæ¨¡æ‹ŸçœŸå®æµ‹é‡è¯¯å·®ï¼ˆÏƒ=0.02ï¼‰\n",
    "- **å½’ä¸€åŒ–å¤„ç†**ï¼šä¿è¯æ•°å€¼ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦\n",
    "\n",
    "#### æ¨¡å‹å±‚ï¼šè½»é‡çº§U-Netæ¶æ„\n",
    "```\n",
    "ç¼–ç å™¨ (Encoder)\n",
    "    â†“ Conv2D Ã— 2 â†’ MaxPooling (Ã— 3 å±‚)\n",
    "    â†“\n",
    "Bottleneck\n",
    "    â†“ Conv2D Ã— 2\n",
    "    â†“\n",
    "è§£ç å™¨ (Decoder)\n",
    "    â†“ UpSampling â†’ Concat â†’ Conv2D Ã— 2 (Ã— 3 å±‚)\n",
    "    â†“\n",
    "è¾“å‡ºå±‚ (Sigmoidæ¿€æ´»)\n",
    "```\n",
    "\n",
    "#### è®­ç»ƒå±‚ï¼šäºŒå€¼åˆ†ç±»æŸå¤±\n",
    "```python\n",
    "æŸå¤±å‡½æ•°: Binary Crossentropy\n",
    "ä¼˜åŒ–å™¨: Adam (lr=0.001)\n",
    "æ­£åˆ™åŒ–: æ—©åœæœºåˆ¶ (patience=10)\n",
    "```\n",
    "\n",
    "#### æ¨ç†å±‚ï¼šé˜ˆå€¼å¼ºåŒ–å¤„ç†\n",
    "```python\n",
    "åå¤„ç†è§„åˆ™:\n",
    "â”œâ”€ é«˜å€¼åŒºåŸŸ (â‰¥0.8) â†’ å‘ä¸Šå–æ•´ = 1.0\n",
    "â”œâ”€ ä½å€¼åŒºåŸŸ (â‰¤0.3) â†’ å‘ä¸‹å–æ•´ = 0.0\n",
    "â””â”€ ä¸­é—´å€¼ (0.3~0.8) â†’ ä¿æŒåŸå€¼\n",
    "```\n",
    "\n",
    "**å¼ºåŒ–æ•ˆæœ**ï¼š\n",
    "- å»é™¤é¢„æµ‹ä¸­çš„æ¨¡ç³Šä¸ç¡®å®šæ€§\n",
    "- å¢å¼ºäºŒå€¼åŒ–åˆ†å‰²æ•ˆæœ\n",
    "- æ¥è¿‘çœŸå®ç‰©ç†æ¨¡å‹ï¼ˆä»‹è´¨å­˜åœ¨/ä¸å­˜åœ¨ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 3. **å¯é…ç½®åŒ–æ¶æ„**\n",
    "```python\n",
    "CONFIG = {\n",
    "    'num_samples': 500,      # æ˜“äºè°ƒæ•´æ•°æ®è§„æ¨¡\n",
    "    'base_filters': 32,      # å¯æ‰©å±•æ¨¡å‹å®¹é‡\n",
    "    'depth': 3,              # çµæ´»è°ƒæ•´ç½‘ç»œæ·±åº¦\n",
    "    'epochs': 60,            # è‡ªé€‚åº”è®­ç»ƒè½®æ•°\n",
    "    'learning_rate': 0.001,  # ç‹¬ç«‹çš„å­¦ä¹ ç‡æ§åˆ¶\n",
    "}\n",
    "```\n",
    "\n",
    "### 4. **æ¨¡å—åŒ–ä»£ç ç»“æ„**\n",
    "```\n",
    "æ•°æ®ç”Ÿæˆæ¨¡å— â”€â”€â†’ æ¨¡å‹æ„å»ºæ¨¡å— â”€â”€â†’ è®­ç»ƒè¯„ä¼°æ¨¡å— â”€â”€â†’ åå¤„ç†ä¸å¯è§†åŒ–\n",
    "  (ç‹¬ç«‹å‡½æ•°)      (ç‹¬ç«‹å‡½æ•°)       (ä¸»ç¨‹åºé€»è¾‘)      (å®Œæ•´çš„ç»“æœè¾“å‡º)\n",
    "```\n",
    "\n",
    "**å¯ç»´æŠ¤æ€§ä¼˜åŠ¿**ï¼š\n",
    "- å„æ¨¡å—ç‹¬ç«‹ï¼Œæ˜“äºå•å…ƒæµ‹è¯•\n",
    "- é…ç½®é›†ä¸­ç®¡ç†ï¼Œä¾¿äºå‚æ•°è°ƒä¼˜\n",
    "- å‡½æ•°æ¥å£æ¸…æ™°ï¼Œæ‰©å±•æ€§å¼º\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## ğŸ”„ å·¥ä½œæµç¨‹\n",
    "\n",
    "```\n",
    "1. æ•°æ®ç”Ÿæˆ\n",
    "   â”œâ”€ ç”Ÿæˆ500ä¸ªåœ†å½¢æ ·æœ¬\n",
    "   â”œâ”€ æ—‹è½¬ä¸å™ªå£°å¢å¼º\n",
    "   â””â”€ å½’ä¸€åŒ–å¤„ç†\n",
    "\n",
    "2. æ¨¡å‹è®­ç»ƒ\n",
    "   â”œâ”€ æ„å»ºè½»é‡çº§U-Net\n",
    "   â”œâ”€ 60ä¸ªepochsï¼ˆå¯èƒ½æ—©åœï¼‰\n",
    "   â””â”€ äºŒå€¼äº¤å‰ç†µä¼˜åŒ–\n",
    "\n",
    "3. æ€§èƒ½è¯„ä¼°\n",
    "   â”œâ”€ è®¡ç®—MSE & MAE\n",
    "   â”œâ”€ ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "   â””â”€ ä¿å­˜æŒ‡æ ‡æ–‡ä»¶\n",
    "\n",
    "4. é¢„æµ‹ä¸å¼ºåŒ–\n",
    "   â”œâ”€ æ¨¡å‹æ¨ç†ï¼ˆåŸå§‹é¢„æµ‹ï¼‰\n",
    "   â”œâ”€ é˜ˆå€¼å¼ºåŒ–å¤„ç†\n",
    "   â””â”€ ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–\n",
    "\n",
    "5. ç»“æœè¾“å‡º\n",
    "   â”œâ”€ training_loss.png (è®­ç»ƒæ›²çº¿)\n",
    "   â”œâ”€ prediction_comparison.png (4å›¾å¯¹æ¯”)\n",
    "   â””â”€ metrics.txt (æ€§èƒ½æŒ‡æ ‡)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ è¿è¡ŒæŒ‡å—\n",
    "\n",
    "### ç¯å¢ƒé…ç½®\n",
    "```bash\n",
    "pip install tensorflow numpy matplotlib\n",
    "```\n",
    "\n",
    "### æ‰§è¡Œè®­ç»ƒ\n",
    "```bash\n",
    "cd src\n",
    "python -c \"exec(open('main.ipynb').read())\"\n",
    "# æˆ–åœ¨Jupyterä¸­è¿è¡Œmain.ipynb\n",
    "```\n",
    "\n",
    "### æŸ¥çœ‹ç»“æœ\n",
    "```bash\n",
    "ls -la results/\n",
    "# è¾“å‡ºï¼š\n",
    "# - training_loss.png\n",
    "# - prediction_comparison.png\n",
    "# - metrics.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ é¢„æœŸç»“æœ\n",
    "\n",
    "### éªŒè¯é›†æŒ‡æ ‡\n",
    "- **MSE**: < 0.01ï¼ˆç›®æ ‡ï¼‰\n",
    "- **MAE**: < 0.05ï¼ˆç›®æ ‡ï¼‰\n",
    "\n",
    "### å¯è§†åŒ–å¯¹æ¯”\n",
    "å››å¼ å¹¶æ’å›¾åƒå±•ç¤ºï¼š\n",
    "1. **Input (Circle)** - è¾“å…¥ç”µç£æ³¢æ•°æ®\n",
    "2. **True Label** - çœŸå®ä»‹è´¨åˆ†å¸ƒ\n",
    "3. **Raw Prediction** - æ¨¡å‹åŸå§‹é¢„æµ‹\n",
    "4. **Enhanced Prediction** - é˜ˆå€¼å¼ºåŒ–åç»“æœ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¬ ç‰©ç†æ„ä¹‰\n",
    "\n",
    "| çŸ©é˜µæ•°å€¼ | ç‰©ç†å«ä¹‰ | ææ–™ä¾‹å­ |\n",
    "|---------|--------|---------|\n",
    "| 0.2 | ä½ä»‹ç”µå¸¸æ•° | ç©ºæ°”ã€çœŸç©º |\n",
    "| 1.0 | é«˜ä»‹ç”µå¸¸æ•° | é™¶ç“·ã€ç»ç’ƒ |\n",
    "\n",
    "**åº”ç”¨åœºæ™¯**ï¼š\n",
    "- åœ°ä¸‹æ°´èµ„æºå‹˜æ¢ï¼ˆGPRé›·è¾¾ï¼‰\n",
    "- åŒ»å­¦æˆåƒï¼ˆMRIä¿¡å·åæ¼”ï¼‰\n",
    "- å·¥ä¸šæ— æŸæ£€æµ‹ï¼ˆç¼ºé™·è¯†åˆ«ï¼‰\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
